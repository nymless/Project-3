# Проектный практикум 3. Учебная задача

## Участники группы

| Участник       |            Почта               |                  Telegram |
|:---------------|:------------------------------:|--------------------------:|
| Домченко М.Н.  |     <domaxnik@gmail.com>       |                    @DMaxr |
| Якунин А.Г.    |  <sanchezz.jakunin@rambler.ru> |              @YakuninAlex |
| Полозов А.П.   |     <artdd52669@gmail.com>     |                @appolozov |
| Бакланов И.Л.  |      <nymless.ib@gmail.com>    |             @ivanbaklanov |
| Липатов С. В.  |       <svlipatov@bk.ru>        |                 @SLipatov |
| Мальцев А. Ю.  |       <malets86@mail.ru>       |        @AlexandrMaltsev86 |

## Описание задачи

Создать нейронную сеть, способную генерировать текстовые отзывы о различных местах на основе определенных входных параметров, таких как категория места, средний рейтинг и ключевые слова.

Данные: <https://github.com/yandex/geo-reviews-dataset-2023>

## Описание решения

Для генерации отзывов была выбрана модель **Gemma-2-2b**, разработанная **Google DeepMind**. Модель основана на архитектуре **трансформер-декодер** (GPT-образная) и сочетает компактность и высокую производительность.

Модель была дообучена (fine-tune) на данных из задачи, при помощи метода **LoRA**.

## Основные особенности модели

* 2 миллиарда параметров и контекстное окно 2048 токенов.
* Улучшения архитектуры:
  * **RoPE** (Rotary Positional Embeddings).
  * **GeGLU** активации.
  * **RMSNorm** нормализация.
  * **Multi-Query Attention** и **Grouped-Query Attention** (GQA) для ускоренного инференса.
  * Чередование локального и глобального внимания.
* Обучена на 2 триллионах токенов из текстов, кода и научных статей.
* Используется **знаниевая дистилляция** (Knowledge distillation) от старших моделей (например **Gemini**), для повышения качества при меньших вычислительных затратах.
* Превосходит аналоги на ключевых тестах: **MMLU**, **GSM8K** и **ARC**.

## Оригинальные статьи

* **Gemma** - <http://arxiv.org/abs/2403.08295>
* **Gemma-2** - <http://arxiv.org/abs/2408.00118>

## Инструкция

Для использования модели (обучения и инференса) нужно:

* Зарегистрироваться в **Hugging Face** - <https://huggingface.co/>.
* Перейти на страницу модели - <https://huggingface.co/google/gemma-2-2b>.
* Согласиться с требованиями по использованию модели компании **Google**.
* В личном кабинете **Hugging Face**, вкладка **Access Tokens**, создать токен.
* В корне проекта создать `.env` файл со следующим содержимым `HUGGING_FACE_ACCESS_TOKEN=Ваш токен`

## Особенности

* Добавлен ноутбук c разведочным анализом данных (EDA) `notebooks/1_eda.ipynb`.
* Добавлен ноутбук с обучением модели на малой выборке данных. Содержит подбор гиперпараметров модели `notebooks/2_fine_tune_gemma-2-2b.ipynb`.
* Добавлен ноутдук с обучением модели на всех данных из датасета. Модель дообучена и сохранена в репозиторий `notebooks/3_all_data_fine_tune.ipynb`.
* Добавлен `Makefile` с основными скиптами для разработки и обучения модели.
* В проект добавлен скрипт `scripts/generate.py`, которые принимает на вход адрес, название, рейтинг и рубрики и возвращает сгенерированный отзыв.
* Добавлена валидация ввода для модели `validation/Inputs.py`.
