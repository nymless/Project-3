{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дообучение Gemma-2-2b с помощью Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer, Trainer,\n",
    "                          TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка переменных из .env файла\n",
    "load_dotenv()\n",
    "# Чтение токена\n",
    "token = os.getenv(\"HUGGING_FACE_ACCESS_TOKEN\")\n",
    "# Устройство для тензорных вычислений и хранения модели в памяти.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1075070e22e4bc8b51d2dd16ea8db78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    token=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество обучаемых параметров до применения LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметров: 2 614 341 888\n",
      "Обучаемых параметров: 2 614 341 888\n"
     ]
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    def pretty_number(num):\n",
    "        return \"{:,}\".format(num).replace(\",\", \" \")\n",
    "\n",
    "    all_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Параметров:\", pretty_number(all_params))\n",
    "    grad_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Обучаемых параметров:\", pretty_number(grad_params))\n",
    "\n",
    "\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим LoRA к модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=6,  # Ранг LoRA\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество обучаемых параметров после применения LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметров: 2 615 539 968\n",
      "Обучаемых параметров: 1 198 080\n"
     ]
    }
   ],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример запроса: Аddress: Екатеринбург, ул. Московская / ул. Волгоградская / ул. Печатников; Name: Московский квартал; Rating: 3; Rubrics: Жилой комплекс.\n",
      "Пример ответа: Text: Московский квартал 2. Шумно : летом по ночам дикие гонки. Грязно : кругом стройки, невозможно открыть окна (16 этаж! ), вечно по району летает мусор. Детские площадки убогие, на большой площади однотипные конструкции. Очень дорогая коммуналка. Часто срабатывает пожарная сигнализация. Жильцы уже не реагируют. В это время, обычно около часа, не работают лифты. Из плюсов - отличная планировка квартир ( Московская 194 ), на мой взгляд. Ремонт от застройщика на 3-. Окна вообще жуть - вместо вентиляции. По соотношению цена/качество - 3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/prepared/data.csv\")\n",
    "df[\"name_ru\"] = df[\"name_ru\"].fillna(\"None\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"\\\\n\", \" \")\n",
    "df = df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "df[\"input\"] = df.apply(\n",
    "    lambda row: f\"Аddress: {row['address']}; Name: {row['name_ru']}; Rating: {row['rating']}; Rubrics: {row['rubrics']}.\",\n",
    "    axis=1,\n",
    ")\n",
    "df[\"output\"] = df.apply(lambda row: f\"Text: {row[\"text\"]}\", axis=1)\n",
    "\n",
    "df = df.drop([\"address\", \"name_ru\", \"rating\", \"rubrics\", \"text\"], axis=1)\n",
    "\n",
    "print(\"Пример запроса:\", df[\"input\"][0])\n",
    "print(\"Пример ответа:\", df[\"output\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
