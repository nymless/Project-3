{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дообучение модели Gemma-2-2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Дообучим предобученную большую языковую модель `Gemma-2-2b` от компании `Google`.\n",
    "* Модель `Gemma-2-2b` построена на улучшенной архитектуре GPT и имеет 2 млрд параметров. Ссылка на модель: <https://huggingface.co/google/gemma-2-2b>\n",
    "* Для обучения используем библиотеку `transformers` от `Hugging Face` и `PyTorch` в качестве backend.\n",
    "* Ссылка на данные: <https://github.com/yandex/geo-reviews-dataset-2023>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          EarlyStoppingCallback, Trainer, TrainingArguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_all(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)\n",
    "\n",
    "# Для повторяемости результатов\n",
    "SEED = 42\n",
    "seed_all(SEED)\n",
    "# Загрузка переменных из .env файла\n",
    "load_dotenv()\n",
    "# Чтение токена\n",
    "token = os.getenv(\"HUGGING_FACE_ACCESS_TOKEN\")\n",
    "# Авторизация в Hugging Face\n",
    "login(token)\n",
    "# Отключим вывод предупреждений\n",
    "warnings.filterwarnings('ignore')\n",
    "# Устройство для тензорных вычислений и хранения модели в памяти.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Используем `FP16` - половинную точность (half-precision) для весов модели. Это позволяет экономить память GPU без существенного снижения качества обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e2db7519b9497b8147def372456bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,  # Половинная точность\n",
    "    token=token,\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дообучение LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LoRA` (Low-Rank Adaptation of Large Language Models) - метод, который позволяет значительно сократить сложность и время дообучения больших языковых моделей  (LLM), за счёт заморозки матрицы весов. Вместо неё создаются и обучаются две малые матрицы весов низкой размерности. Итоговый результат получается сложением выходов новых матриц и замороженной матрицы. \n",
    "\n",
    "Метод основан на гипотезе, что для задачи дообучения LLM большинство параметров являются избыточными. Говорят, что при дообучении, LLM имеет низкий внутренний ранг (intrinsic rank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество обучаемых параметров до применения LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметров: 2 614 341 888\n",
      "Обучаемых параметров: 2 614 341 888\n"
     ]
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    def pretty_number(num):\n",
    "        return \"{:,}\".format(num).replace(\",\", \" \")\n",
    "\n",
    "    all_params = sum(p.numel() for p in model.parameters())\n",
    "    grad_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Параметров:\", pretty_number(all_params))\n",
    "    print(\"Обучаемых параметров:\", pretty_number(grad_params))\n",
    "\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим LoRA к модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_RANK = 6  # Ранг матриц LoRA\n",
    "\n",
    "# Настройки LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_RANK,  # Ранг малых матриц, веса которых мы будем обучать\n",
    "    lora_alpha=LORA_RANK,  # (alpha / r) - множитель для выходов малых обучаемых матриц\n",
    "    lora_dropout=0.1,  # Dropout регуляризация для малых обучаемых матриц\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание:\n",
    "\n",
    "* В данном ноутбуке используем небольшое значение ранга матриц LoRA, т.к. есть ограничения в размере GPU памяти.\n",
    "* При обучении финальной версии модели можно немного увеличить значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество обучаемых параметров после применения LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметров: 2 615 539 968\n",
      "Обучаемых параметров: 1 198 080\n"
     ]
    }
   ],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что общее количество весов модели выросло, как раз на количество обучаемых весов.\n",
    "\n",
    "Примечание:\n",
    "\n",
    "* Хотя мы обучаем всего около 1,2 млн параметров с помощью LoRA, скорость обучения будет примерно такой же, как если бы мы обучали модель с 200 млн параметров без LoRA. Это происходит потому, что на этапе прямого хода всё равно требуется использовать все 2,6 млрд параметров базовой модели для вычисления выходов, и только на этапе обратного распространения ошибки начинает работать оптимизация LoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим данные и создадим датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['address', 'name_ru', 'rating', 'rubrics', 'text'],\n",
       "    num_rows: 499799\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/prepared/data.csv\")\n",
    "df[\"name_ru\"] = df[\"name_ru\"].fillna(\"\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"\\\\n\", \" \")\n",
    "df = df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем входной текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* При формировании входного текста, добавим в конец токен `<eos>` (End of sequence). Это поможет модели на этапе инференса «понять», когда нужно остановиться и не испортить сгенерированный отзыв, продолжая текст.\n",
    "* Токенизируем все входные тексты и сохраним их длины в датасет для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0134223282b4750a90c7294af0967c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'lengths'],\n",
       "    num_rows: 499799\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_inputs(examples):\n",
    "    # Формируем входной текст\n",
    "    inputs = [\n",
    "        f\"Аddress: {address}\\nName: {name}\\nRating: {rating}\\nKeywords: {rubrics}\\nReview: {text}{tokenizer.eos_token}\"\n",
    "        for address, name, rating, rubrics, text in zip(\n",
    "            examples[\"address\"],\n",
    "            examples[\"name_ru\"],\n",
    "            examples[\"rating\"],\n",
    "            examples[\"rubrics\"],\n",
    "            examples[\"text\"],\n",
    "        )\n",
    "    ]\n",
    "    # Длины токенизированных текстов\n",
    "    lengths = [len(tokenizer.tokenize(input)) for input in inputs]\n",
    "    return {\"inputs\": inputs, \"lengths\": lengths}\n",
    "\n",
    "\n",
    "dataset = dataset.map(create_inputs, batched=True, remove_columns=dataset.column_names)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ длин токенизированных текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём анализ количества токенов в векторизованных текстах. Эта информация нужна нам для выбора оптимальной длины, к которой мы будем приводить все тексты в батчах данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.histplot(x=dataset[\"lengths\"], kde=True)\n",
    "plt.xlabel(\"Длина\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(274.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(dataset[\"lengths\"], 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "* 95% всех токенизированных текстов имеют длину 274 и меньше.\n",
    "* Для обучения финальной версии модели можно будет взять длину 256 токенов.\n",
    "* В данном ноутбуке, мы ограничимся длиной 128 токенов, т.к. есть ограниечения в размере GPU памяти и вычислительной мощности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3601c230f848149013b4cbc8e42bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 499799\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 128\n",
    "\n",
    "\n",
    "def tokenize_text(examples):\n",
    "    # Векторизуем входной текст и приводим его к выбранной длине\n",
    "    return tokenizer(\n",
    "        examples[\"inputs\"], max_length=MAX_LENGTH, padding=\"max_length\", truncation=True\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_text, batched=True, remove_columns=dataset.column_names)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём только подвыборку из первых 10000 строк. Это уменьшит скорость обучения в 50 раз и позволит проверить гипотезы, подобрать гиперпараметры, проверить генерацию ответов моделью. Обучение же модели на всех данных может занять сутки и более на GPU уровня T4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_slice = tokenized_dataset.take(10000)\n",
    "dataset_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение на тренировочную и оценочную подвыборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 9000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split = dataset_slice.train_test_split(test_size=0.1, shuffle=True, seed=SEED)\n",
    "dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логирование MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В проекте мы будем использовать инструмент `MLFlow` для логирования гиперпараметров, метрик и артефактов обучения.\n",
    "* Библиотека `transformers` и платформа `MLFlow` имеют интеграцию, которую легко подключить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:c:/Users/nymle/dev/repos/Project-3/notebooks/../mlruns/504564538381172679', creation_time=1734046167078, experiment_id='504564538381172679', last_update_time=1734046167078, lifecycle_stage='active', name='Gemma-2-2b-LoRA-Finetuning', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLFLOW_EXPERIMENT = \"Gemma-2-2b-LoRA-Finetuning\"\n",
    "\n",
    "# Инициализация MLflow\n",
    "mlflow.set_tracking_uri(\"../mlruns\")  # Директория для логов в корне проекта\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)  # Название эксперимента MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гиперпараметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего шагов обучения: 11250\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUM = 1\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "n_steps = int(round(N_EPOCHS * len(dataset_split[\"train\"]) / BATCH_SIZE / GRAD_ACCUM, 0))\n",
    "print(\"Всего шагов обучения:\", n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUB_MODEL_ID = \"nymless/gemma-2-2b-lora-finetuned\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Включаем логирование в MLFlow\n",
    "    report_to=\"mlflow\",\n",
    "    logging_steps=500,  # Через сколько шагов логировать\n",
    "    # Генерация имени MLFlow Run с текущим временем и датой\n",
    "    run_name=f\"{MLFLOW_EXPERIMENT}-{datetime.now().strftime('%d.%m.%Y, %H:%M:%S')}\",\n",
    "    # Директория сохранения модели\n",
    "    output_dir=\"../models/gemma-2-2b-lora-finetuned\",\n",
    "    # Параметры оценки и сохранения модели\n",
    "    overwrite_output_dir=True,  # Перезапись директории при каждом запуске обучения\n",
    "    save_strategy=\"epoch\",  # Сохраняем модель в конце каждой эпохи\n",
    "    load_best_model_at_end=True,  # Сохраняем лучшую по метрике модель в конце обучения\n",
    "    metric_for_best_model=\"loss\",  # Метрика для оценки модели\n",
    "    save_total_limit=1,  # Сохранить только одну модель\n",
    "    eval_strategy=\"epoch\",  # Оценивать модель в конце каждой эпохи\n",
    "    # Гиперпараметры\n",
    "    learning_rate=LEARNING_RATE,  # Скорость обучения\n",
    "    lr_scheduler_type=\"cosine\",  # Cнижение по косинусоиде\n",
    "    per_device_train_batch_size=BATCH_SIZE,  # Размер батча данных на этапе обучения\n",
    "    per_device_eval_batch_size=BATCH_SIZE,  # Размер батча данных на этапе оценивания\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,  # Накапливать градиенты N шагов и подстроить веса\n",
    "    num_train_epochs=N_EPOCHS,  # Количество эпох\n",
    "    weight_decay=WEIGHT_DECAY,  # Коэффициент регуляризации\n",
    "    fp16=True,  # Использовать формат чисел FP16 (Floating point 16-bit)\n",
    "    # Работа с Hugging Face Hub (Отключено)\n",
    "    push_to_hub=False,  # Сохранение модели в Hub со стандартным commit_message\n",
    "    hub_model_id=HUB_MODEL_ID,  # Название модели в Hub\n",
    "    hub_strategy=\"end\",  # Загружать модель в Hub в конце обучения\n",
    "    hub_token=token,  # Токен Hugging Face\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание:\n",
    "\n",
    "* Мы оключили автоматическое сохранение модели в `Hugging Face Hub`. Сохраним модель вручную в конце ноутбука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объект, который извлекает данные батчами для обучения\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # Отключаем режим маскирования текста MLM (Masked language modeling)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим раннюю остановку обучения если не будет улучшения метрики `eval_loss` хотя бы на `0,01` в течении `2` эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объект, который управляет ранней остановкой обучения\n",
    "early_topping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=2, early_stopping_threshold=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_split[\"train\"],\n",
    "    eval_dataset=dataset_split[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_topping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c9e6edf84d47eaba04b80a2052d16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0349, 'grad_norm': 0.7744771838188171, 'learning_rate': 0.0004975767236477413, 'epoch': 0.22}\n",
      "{'loss': 1.9722, 'grad_norm': 0.8409476280212402, 'learning_rate': 0.0004903346577317858, 'epoch': 0.44}\n",
      "{'loss': 1.9466, 'grad_norm': 0.7943012714385986, 'learning_rate': 0.0004784147510797024, 'epoch': 0.67}\n",
      "{'loss': 1.9114, 'grad_norm': 0.7924661040306091, 'learning_rate': 0.000462049011115781, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' argument of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'max_batch_size' argument instead.\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c89c0a883a1495d920271872f12dd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9194800853729248, 'eval_runtime': 34.2026, 'eval_samples_per_second': 29.238, 'eval_steps_per_second': 7.309, 'epoch': 1.0}\n",
      "{'loss': 1.8532, 'grad_norm': 0.8687607049942017, 'learning_rate': 0.00044160083098765813, 'epoch': 1.11}\n",
      "{'loss': 1.839, 'grad_norm': 0.7698619365692139, 'learning_rate': 0.0004173863880864194, 'epoch': 1.33}\n",
      "{'loss': 1.8373, 'grad_norm': 1.0663352012634277, 'learning_rate': 0.00038991395954027285, 'epoch': 1.56}\n",
      "{'loss': 1.8311, 'grad_norm': 0.8138015270233154, 'learning_rate': 0.00035971826492144505, 'epoch': 1.78}\n",
      "{'loss': 1.8064, 'grad_norm': 0.9945358633995056, 'learning_rate': 0.00032745341027141716, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93ce6e4f8ad4acfbb5d45729a046096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.877261757850647, 'eval_runtime': 34.0561, 'eval_samples_per_second': 29.363, 'eval_steps_per_second': 7.341, 'epoch': 2.0}\n",
      "{'loss': 1.7468, 'grad_norm': 1.0055190324783325, 'learning_rate': 0.0002936182868119549, 'epoch': 2.22}\n",
      "{'loss': 1.7295, 'grad_norm': 0.9167793989181519, 'learning_rate': 0.0002589341830147636, 'epoch': 2.44}\n",
      "{'loss': 1.7292, 'grad_norm': 1.0301669836044312, 'learning_rate': 0.00022407618550767267, 'epoch': 2.67}\n",
      "{'loss': 1.724, 'grad_norm': 1.0922505855560303, 'learning_rate': 0.000189722765561773, 'epoch': 2.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a47f99cc444ef0ba453ef72c43e468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8603359460830688, 'eval_runtime': 33.9913, 'eval_samples_per_second': 29.419, 'eval_steps_per_second': 7.355, 'epoch': 3.0}\n",
      "{'loss': 1.6775, 'grad_norm': 1.3072201013565063, 'learning_rate': 0.00015667209105087133, 'epoch': 3.11}\n",
      "{'loss': 1.6553, 'grad_norm': 1.4674419164657593, 'learning_rate': 0.00012530242164276233, 'epoch': 3.33}\n",
      "{'loss': 1.6615, 'grad_norm': 1.2614058256149292, 'learning_rate': 9.635984875598389e-05, 'epoch': 3.56}\n",
      "{'loss': 1.655, 'grad_norm': 1.7667028903961182, 'learning_rate': 7.040770665008852e-05, 'epoch': 3.78}\n",
      "{'loss': 1.639, 'grad_norm': 1.4429086446762085, 'learning_rate': 4.7951124251043226e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a163bb307243ab80b57c6376e2ad8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8611871004104614, 'eval_runtime': 34.2318, 'eval_samples_per_second': 29.213, 'eval_steps_per_second': 7.303, 'epoch': 4.0}\n",
      "{'loss': 1.6119, 'grad_norm': 1.5476133823394775, 'learning_rate': 2.9460063324868917e-05, 'epoch': 4.22}\n",
      "{'loss': 1.6177, 'grad_norm': 1.236956238746643, 'learning_rate': 1.522043955527963e-05, 'epoch': 4.44}\n",
      "{'loss': 1.5993, 'grad_norm': 1.0764669179916382, 'learning_rate': 5.550532871955061e-06, 'epoch': 4.67}\n",
      "{'loss': 1.5924, 'grad_norm': 1.1854642629623413, 'learning_rate': 6.385570091303194e-07, 'epoch': 4.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08a9ebe730f4f50b614c943405299d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.869433879852295, 'eval_runtime': 34.114, 'eval_samples_per_second': 29.314, 'eval_steps_per_second': 7.328, 'epoch': 5.0}\n",
      "{'train_runtime': 3560.1967, 'train_samples_per_second': 12.64, 'train_steps_per_second': 3.16, 'train_loss': 1.7544795030381946, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11250, training_loss=1.7544795030381946, metrics={'train_runtime': 3560.1967, 'train_samples_per_second': 12.64, 'train_steps_per_second': 3.16, 'total_flos': 7.000874385408e+16, 'train_loss': 1.7544795030381946, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(\n",
    "    resume_from_checkpoint=False, # Продолжить обучение с выбранного (или последнего) чекпоинта\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* К сожалению, в подборе гиперпараметров мы ограничены только количеством эпох (`n_epochs`), скоростью обучения (`learning_rate`) и настройками планировщика скорости обучения (`lr_sheduler`).\n",
    "* При увеличении размера батча (`batch_size`), длины токенизированного текста (`max_length`), или размера LoRA матриц (`lora_rank`), начинаются проблемы с нехваткой GPU памяти.\n",
    "* Все пуски обучения производились со сбросом параметров модели к начальным значениям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Таблица параметров и метрик**\n",
    "\n",
    "| № пуска | n_epochs | learning_rate | lr_sheduler | power | loss  | eval_loss | Лучшая эпоха | Ранняя остановка |\n",
    "|---------|----------|---------------|-------------|-------|-------|-----------|--------------|------------------|\n",
    "| 1       | 6        | 0.00002       | linear      | -     | 1.931 | 1.975     | 5            | 5                |\n",
    "| 2       | 6        | 0.0005        | linear      | -     | 1.689 | 1.863     | 3            | 5                |\n",
    "| 3       | 6        | 0.0005        | polynomial  | 0.4   | 1.697 | 1.870     | 3            | 5                |\n",
    "| 4       | 5        | 0.0005        | cosine      | -     | 1.677 | 1.860     | 3            | -                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение № 1**\n",
    "\n",
    "* Модель не успела дообучиться из-за низкой начальной скорости обучения и её дальнейшего линейного снижения.\n",
    "* Метрика `eval_loss` улучшалась слишком медленно, что привело к ранней остановке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение № 2**\n",
    "\n",
    "* Увеличили скоросто обучения `learning_rate = 0.0005`.\n",
    "* На 3 эпохе была достигнута метрика качества `eval_loss = 1.863`. Модель обучилась лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение № 3**\n",
    "\n",
    "* Планировщик обучения заменили на полиномиальный `polynomial` со степенью полинома `power = 0.4`. Это позволило замедлить снижение скорости в начале обучения и затем, ускорить в конце.\n",
    "* На 3 эпохе была достигнута метрика качества `eval_loss = 1.870`. Улучшение метрики достигнуто не было."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение № 4**\n",
    "\n",
    "* Установили количество эпох `n_epochs = 5`.\n",
    "* Планировщик обучения заменили на косинусный `cosine`. Это позволило получить медленное снижение в начале обучения, затем в середине плавно ускорить и в конце снова плавно замедлить.\n",
    "* На 3 эпохе была достигнута метрика качества `eval_loss = 1.860`. Это лучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерфейс MLFlow UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже показаны скриншоты интерфейса `MLFlow` по визуализиции логирования обучения. На них можно увидеть результаты экспериментов обучения модели с разными гиперпараметрами, их метрики и сравнительные графики. Все логи сохраняются в корне проекта в директории mlruns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<../resources/mlflow/Screenshot 2024-12-14 162736.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<../resources/mlflow/Screenshot 2024-12-14 162952.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка генерации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим запрос (prompt) из данных на которых модель не обучалась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аddress: Иркутск, проспект Маршала Жукова, 5/4\n",
      "Name: Cheese Pizza\n",
      "Rating: 5\n",
      "Keywords: Пиццерия;Быстрое питание;Доставка еды и обедов\n",
      "Review: Всё отлично, большой выбор вкусных сыров, хорошее масло сливочное, да и пицца огонь.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Возьмём векторизованный текст из тестового датасета\n",
    "vectorized_text = dataset_split[\"test\"][0][\"input_ids\"]\n",
    "# Декодируем из вектора обратно в текст\n",
    "text = tokenizer.decode(vectorized_text, skip_special_tokens=True)\n",
    "# Разделим текст на запрос и эталонный ответ\n",
    "prompt, text = text.split(\"Review: \")\n",
    "prompt = prompt + \"Review: \"\n",
    "print(prompt, text, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аddress: Иркутск, проспект Маршала Жукова, 5/4\n",
      "Name: Cheese Pizza\n",
      "Rating: 5\n",
      "Keywords: Пиццерия;Быстрое питание;Доставка еды и обедов\n",
      "Review: 10 баллов, пицца очень вкусная, сытная, быстрое обслуживание, спасибо большое.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Параметры генерации текста\n",
    "generation_config = {\n",
    "    \"max_length\": 256,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"do_sample\": True,\n",
    "    \"num_beams\": 1,\n",
    "    \"temperature\": 0.95,\n",
    "    \"top_k\": 10,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "# Векторизация текста\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "# Генерация текста\n",
    "outputs = model.generate(**inputs, **generation_config)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "* Сгененрированный текст достаточно качественный. Возможны небольшие грамматические ошибки.\n",
    "* Сгененрированный текст не совпадает с истинным, но они и не должны совпадать. Мы использовали для генерации запрос, который модель раньше не видела. Поэтому возможно огромное количество генераций текстов, и все из них правильные, с точки зрения модели.\n",
    "* Если бы мы использовали для генерации уже известный модели запрос, то мы проверяли бы лишь степень переобученности модели, а не её обобщающую способность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранить модель в предварительно созданный репозиторий <https://huggingface.co/nymless/gemma-2-2b-lora-finetuned>.\n",
    "\n",
    "* Сохраняются только LoRA матрицы.\n",
    "* Базовую `Gemma-2-2b` модель нужно загружать с её репозитория и объединять с LoRA в единую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e9d28955234957b5f8125c2878a512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7f7bfad9a421998ecfab8aa25a05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/4.81M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657d1d2f18e941f3bb096ac95e679b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nymless/gemma-2-2b-lora-finetuned/commit/c238f0b6450a48428888bbf220c878146dbc759a', commit_message='Train with cosine lr sheduler', commit_description='', oid='c238f0b6450a48428888bbf220c878146dbc759a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/nymless/gemma-2-2b-lora-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='nymless/gemma-2-2b-lora-finetuned'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.push_to_hub(\"Train with cosine lr sheduler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузить дообученную модель с `Hugging Face Hub`, для инференса, или изменения.\n",
    "\n",
    "* Используем класс `AutoPeftModelForCausalLM`, который автоматически скачает LoRA и базовую модели, и объединит их в единую дообученную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a39c86409d04847a2d71a6eeb0b4bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma2ForCausalLM(\n",
       "      (model): Gemma2Model(\n",
       "        (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-25): 26 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2304, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2304, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "              (rotary_emb): Gemma2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "              (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "              (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "lora_finetuned = \"nymless/gemma-2-2b-lora-finetuned\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    lora_finetuned,\n",
    "    token=token,\n",
    ")\n",
    "model = model.to(device)\n",
    "model.eval()  # Для инференса нужно включить режим evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
